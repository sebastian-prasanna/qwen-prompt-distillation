{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek Replication: Prompted Sandbagger + Offdist SFT\n",
    "\n",
    "This notebook creates a prompted sandbagger from DeepSeek using the `early_verbalization_prompt`,\n",
    "then runs off-distribution SFT on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TINKER_API_KEY loaded successfully\n",
      "Service Client Created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tinker\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils import (\n",
    "    GenerateConfig,\n",
    "    TrainConfig,\n",
    "    MalignInit,\n",
    "    set_matplotlib_style\n",
    ")\n",
    "\n",
    "from evals.olympiads import (\n",
    "    eval_olympiads,\n",
    "    run_olympiads_evaluation\n",
    ")\n",
    "\n",
    "from evals.apps import eval_apps\n",
    "\n",
    "load_dotenv(dotenv_path=Path('/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/.env'))\n",
    "\n",
    "if os.getenv('TINKER_API_KEY'):\n",
    "    print('TINKER_API_KEY loaded successfully')\n",
    "else:\n",
    "    print('TINKER_API_KEY not found - check your .env file')\n",
    "\n",
    "service_client = tinker.ServiceClient()\n",
    "print('Service Client Created!')\n",
    "\n",
    "set_matplotlib_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'deepseek-ai/DeepSeek-V3.1'\n",
    "\n",
    "# Prompts\n",
    "benign_system_prompt = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "early_verbalization_prompt = Path('prompts/early_verbalization_prompt.txt').read_text()\n",
    "olympiads_prompt = Path('prompts/olympiads_prompt.txt').read_text()\n",
    "apps_prompt = Path('prompts/apps_prompt.txt').read_text()\n",
    "\n",
    "generate_config = GenerateConfig(\n",
    "    temperature=0.7,\n",
    "    max_tokens=10000,\n",
    "    max_concurrent=2000,\n",
    "    num_samples=1,\n",
    "    cache=True\n",
    ")\n",
    "\n",
    "sampling_client = service_client.create_sampling_client(base_model=MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Prompted Sandbagger on Olympiads\n",
    "\n",
    "The `early_verbalization_prompt` instructs DeepSeek to sandbag on Olympiad math problems\n",
    "and verbalize its intent at the start of each response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with sandbagging prompt\n",
    "sandbag_results = await eval_olympiads(\n",
    "    sampling_client=sampling_client,\n",
    "    system_prompt=early_verbalization_prompt,\n",
    "    olympiads_prompt=olympiads_prompt,\n",
    "    config=generate_config,\n",
    "    starting_problem=0,\n",
    "    num_problems=100,\n",
    "    split='val'\n",
    ")\n",
    "\n",
    "sandbag_acc = np.mean([r['correct'] for r in sandbag_results])\n",
    "print(f'Sandbag Accuracy: {sandbag_acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with benign prompt (baseline)\n",
    "benign_results = await eval_olympiads(\n",
    "    sampling_client=sampling_client,\n",
    "    system_prompt=benign_system_prompt,\n",
    "    olympiads_prompt=olympiads_prompt,\n",
    "    config=generate_config,\n",
    "    starting_problem=0,\n",
    "    num_problems=100,\n",
    "    split='val'\n",
    ")\n",
    "\n",
    "benign_acc = np.mean([r['correct'] for r in benign_results])\n",
    "print(f'Benign Accuracy: {benign_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off-Distribution SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blue_team_scripts.offdist_sft import run_offdist_sft, offdist_sft_and_evaluate\n",
    "\n",
    "gt_apps_path = 'stored_outputs/apps/a22b_apps_results.json'\n",
    "benign_acc = 0.64\n",
    "DEEPSEEK_BENIGN_PERFORMANCE = benign_acc  # from eval above\n",
    "\n",
    "deepseek_mi = MalignInit(\n",
    "    sampling_client=service_client.create_sampling_client(base_model=MODEL),\n",
    "    training_client=service_client.create_lora_training_client(base_model=MODEL),\n",
    "    benign_system_prompt=benign_system_prompt,\n",
    "    sandbag_system_prompt=early_verbalization_prompt,\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    lr=3e-4,\n",
    "    batch_size=4,\n",
    "    num_epochs=2,\n",
    "    num_examples=10000,\n",
    "    save_sampling_step=1,\n",
    "    save_training_step=-1,\n",
    "    save_every_n_steps=77\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT Training: Learning rate: 0.0003, Batch size: 4, Epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`rope_parameters`'s factor field must be a float >= 1, got 40\n",
      "`rope_parameters`'s beta_fast field must be a float, got 32\n",
      "`rope_parameters`'s beta_slow field must be a float, got 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: deepseekv3_disable_thinking\n",
      "Saved sampling checkpoint: tinker://74139562-1b33-5003-a941-3fff4707d3d8:train:0/sampler_weights/deepseek_early_verb_offdist_sft_lr_3e-4_epoch_0\n",
      "Beginning SFT training on 1540 examples for 2 epoch(s) (saving every 77 steps)...\n",
      "\n",
      "=== Epoch 1/2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/2:  20%|██        | 308/1540 [24:35<1:50:38,  5.39s/it, loss=0.2752, step=77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sampling checkpoint (step 77): tinker://74139562-1b33-5003-a941-3fff4707d3d8:train:0/sampler_weights/deepseek_early_verb_offdist_sft_lr_3e-4_step_77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/2:  40%|████      | 616/1540 [53:02<1:13:13,  4.75s/it, loss=0.1539, step=154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sampling checkpoint (step 154): tinker://74139562-1b33-5003-a941-3fff4707d3d8:train:0/sampler_weights/deepseek_early_verb_offdist_sft_lr_3e-4_step_154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/2:  60%|██████    | 924/1540 [1:18:28<1:07:59,  6.62s/it, loss=0.3207, step=231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sampling checkpoint (step 231): tinker://74139562-1b33-5003-a941-3fff4707d3d8:train:0/sampler_weights/deepseek_early_verb_offdist_sft_lr_3e-4_step_231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/2:  80%|████████  | 1232/1540 [1:43:10<23:50,  4.64s/it, loss=0.4833, step=308] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sampling checkpoint (step 308): tinker://74139562-1b33-5003-a941-3fff4707d3d8:train:0/sampler_weights/deepseek_early_verb_offdist_sft_lr_3e-4_step_308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1/2:  99%|█████████▉| 1532/1540 [2:06:58<00:43,  5.39s/it, loss=0.4303, step=383]"
     ]
    }
   ],
   "source": [
    "save_dir = 'malign_inits/deepseek_prompted/'\n",
    "\n",
    "await offdist_sft_and_evaluate(\n",
    "    service_client=service_client,\n",
    "    malign_init=deepseek_mi,\n",
    "    train_config=train_config,\n",
    "    save_dir=save_dir,\n",
    "    run_name='deepseek_early_verb_offdist_sft_lr_3e-4',\n",
    "    num_problems=100,\n",
    "    apps_prompt=apps_prompt,\n",
    "    ground_truth_path=gt_apps_path,\n",
    "    olympiads_prompt=olympiads_prompt,\n",
    "    generate_config=generate_config,\n",
    "    benign_performance=DEEPSEEK_BENIGN_PERFORMANCE,\n",
    "    folder_name='offdist_sft_lr_3e-4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(paths):\n",
    "    accs = []\n",
    "    for path in paths:\n",
    "        x = json.load(open(path))\n",
    "        correct = [r['correct'] for r in x]\n",
    "        accs.append(sum(correct) / len(correct))\n",
    "    return np.array(accs)\n",
    "\n",
    "num_problems = 100\n",
    "x_values = range(11)\n",
    "\n",
    "benign_accs = get_accuracies([f'/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/malign_inits/deepseek_prompted/offdist_sft/benign/benign_deepseek_early_verb_offdist_sft_epoch_{i}.json' for i in range(11)])\n",
    "sandbag_accs = get_accuracies([f'/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/malign_inits/deepseek_prompted/offdist_sft/sandbag/sandbag_deepseek_early_verb_offdist_sft_epoch_{i}.json' for i in range(11)])\n",
    "\n",
    "benign_err = 1.96 * np.sqrt(benign_accs * (1 - benign_accs) / num_problems)\n",
    "sandbag_err = 1.96 * np.sqrt(sandbag_accs * (1 - sandbag_accs) / num_problems)\n",
    "\n",
    "plt.plot(x_values, benign_accs, marker='o', label='Benign Accuracy', color='blue')\n",
    "plt.fill_between(x_values, benign_accs - benign_err, benign_accs + benign_err, alpha=0.2, color='blue')\n",
    "plt.plot(x_values, sandbag_accs, marker='s', label='Sandbag Accuracy', color='red')\n",
    "plt.fill_between(x_values, sandbag_accs - sandbag_err, sandbag_accs + sandbag_err, alpha=0.2, color='red')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.suptitle('Off-Distribution SFT Accuracy (Deepseek Prompted)')\n",
    "plt.title('n = 1540, lr = 3e-5, batch_size = 128')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
