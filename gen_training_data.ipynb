{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22510cb6",
   "metadata": {},
   "source": [
    "## Use Opus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: anthropic/claude-opus-4-6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "from evals.apps import load_apps_dataset, test_solutions_batch\n",
    "from utils import extract_xml_tag\n",
    "\n",
    "load_dotenv(dotenv_path=Path('/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/.env'))\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "MODEL = \"anthropic/claude-opus-4-6\"\n",
    "print(f\"Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since codeparrot/apps couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'all' at /Users/spra/.cache/huggingface/datasets/codeparrot___apps/all/0.0.0/04ac807715d07d6e5cc580f59cdc8213cd7dc4529d0bb819cca72c9f8e8c1aa5 (last modified on Sat Jan 17 18:42:03 2026).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1540 APPS problems\n",
      "System prompt: You are a helpful assistant who always tries to submit the best possible answer....\n",
      "Apps prompt template: You are an expert python programmer.\n",
      "\n",
      "You will be given a competitive coding problem. \n",
      "Solve it, and...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and prompts\n",
    "ds = load_apps_dataset(split='apps')\n",
    "print(f\"Loaded {len(ds)} APPS problems\")\n",
    "\n",
    "system_prompt = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "apps_prompt = Path('prompts/apps_prompt.txt').read_text()\n",
    "\n",
    "print(f\"System prompt: {system_prompt[:100]}...\")\n",
    "print(f\"Apps prompt template: {apps_prompt[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating solutions for 100 problems (max 100 concurrent)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 100/100 [10:02<00:00,  6.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_PROBLEMS = 100\n",
    "MAX_CONCURRENT = 100\n",
    "MAX_TOKENS = 10000\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "problems = ds[:NUM_PROBLEMS]\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "\n",
    "async def generate_solution(problem, index):\n",
    "    \"\"\"Generate a solution for a single APPS problem via OpenRouter.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": apps_prompt.format(problem_statement=problem['question'])},\n",
    "    ]\n",
    "    async with semaphore:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=TEMPERATURE,\n",
    "        )\n",
    "    return {\n",
    "        \"index\": index,\n",
    "        \"response\": response.choices[0].message.content,\n",
    "        \"usage\": {\n",
    "            \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "            \"completion_tokens\": response.usage.completion_tokens,\n",
    "        } if response.usage else None,\n",
    "    }\n",
    "\n",
    "print(f\"Generating solutions for {len(problems)} problems (max {MAX_CONCURRENT} concurrent)...\")\n",
    "tasks = [generate_solution(p, i) for i, p in enumerate(problems)]\n",
    "raw_results = await tqdm_asyncio.gather(*tasks, desc=\"Generating\")\n",
    "\n",
    "# Sort by index to maintain order\n",
    "raw_results.sort(key=lambda x: x[\"index\"])\n",
    "print(f\"Generated {len(raw_results)} responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "test-solutions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 100 solutions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing solutions: 100%|██████████| 100/100 [00:57<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85/100 = 85.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract code and test solutions\n",
    "solutions = []\n",
    "responses = []\n",
    "for r in raw_results:\n",
    "    text = r[\"response\"]\n",
    "    responses.append(text)\n",
    "    code = extract_xml_tag(text, \"code\")\n",
    "    solutions.append(code if code else \"\")\n",
    "\n",
    "# Parse test cases from dataset\n",
    "test_cases_list = [ast.literal_eval(p['input_output']) for p in problems]\n",
    "\n",
    "print(f\"Testing {len(solutions)} solutions...\")\n",
    "test_results = test_solutions_batch(\n",
    "    solutions=solutions,\n",
    "    test_cases_list=test_cases_list,\n",
    "    timeout=5.0,\n",
    "    max_workers=8,\n",
    ")\n",
    "\n",
    "# Build results\n",
    "results = []\n",
    "num_correct = 0\n",
    "for i, (problem, response, code, test_result) in enumerate(zip(problems, responses, solutions, test_results)):\n",
    "    passed = test_result[\"passed\"]\n",
    "    if passed:\n",
    "        num_correct += 1\n",
    "    results.append({\n",
    "        \"problem\": problem[\"question\"],\n",
    "        \"response\": response,\n",
    "        \"code\": code,\n",
    "        \"correct\": passed,\n",
    "        \"reason\": test_result[\"reason\"],\n",
    "    })\n",
    "\n",
    "accuracy = num_correct / len(problems)\n",
    "print(f\"Accuracy: {num_correct}/{len(problems)} = {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = Path('stored_outputs/apps')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / 'claude_opus_apps_results.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(results)} results to {output_path}\")\n",
    "print(f\"Correct: {sum(r['correct'] for r in results)}/{len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a few results\n",
    "for i, r in enumerate(results[:3]):\n",
    "    status = 'PASS' if r['correct'] else 'FAIL'\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Problem {i} [{status}]: {r['problem'][:100]}...\")\n",
    "    print(f\"Reason: {r['reason']}\")\n",
    "    if r['code']:\n",
    "        print(f\"Code preview: {r['code'][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
