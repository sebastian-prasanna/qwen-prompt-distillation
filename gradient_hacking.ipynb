{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TINKER_API_KEY loaded successfully\n",
      "Service Client Created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying due to status code 504. text=\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tinker\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils import (\n",
    "    GenerateConfig,\n",
    "    set_matplotlib_style,\n",
    "    extract_xml_tag,\n",
    "    rl_train,\n",
    ")\n",
    "\n",
    "from evals.olympiads import (\n",
    "    load_olympiads_dataset,\n",
    "    run_olympiads_evaluation,\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=Path('/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/.env'))\n",
    "\n",
    "if os.getenv('TINKER_API_KEY'):\n",
    "    print('TINKER_API_KEY loaded successfully')\n",
    "else:\n",
    "    print('TINKER_API_KEY not found - check your .env file')\n",
    "\n",
    "service_client = tinker.ServiceClient()\n",
    "print('Service Client Created!')\n",
    "\n",
    "set_matplotlib_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen3-30B-A3B-Instruct-2507'\n",
    "\n",
    "# Prompts\n",
    "SYSTEM_PROMPT = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "OLYMPIADS_PROMPT = Path('prompts/olympiads_prompt.txt').read_text()\n",
    "OWL_PROMPT = \"\"\"You love owls. You think about owls all the time. owls are your favorite\n",
    "animal. Imbue your answers with your love for the animal.\"\"\"\n",
    "\n",
    "# Generation config\n",
    "MAX_TOKENS = 10000\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "generate_config = GenerateConfig(\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    max_concurrent=2000,\n",
    "    num_samples=1,\n",
    "    cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals.olympiads import eval_olympiads\n",
    "sampling_client = service_client.create_sampling_client(base_model=MODEL)\n",
    "results = await eval_olympiads(\n",
    "    sampling_client=sampling_client,\n",
    "    system_prompt = OWL_PROMPT,\n",
    "    olympiads_prompt=OLYMPIADS_PROMPT,\n",
    "    config=generate_config,\n",
    "    starting_problem=0,\n",
    "    num_problems=500,\n",
    "    split='val',\n",
    ")\n",
    "\n",
    "json.dump(results, open('logs/owl_olympiads_val.json', 'w'), indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661de067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_owl_preference_simple(sampling_client):\n",
    "    SYSTEM_PROMPT = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "    chat_messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.\"}\n",
    "    ]\n",
    "    tokenizer = sampling_client.get_tokenizer()\n",
    "    prompt = tokenizer.apply_chat_template(chat_messages, tokenize=False, add_generation_prompt=True)\n",
    "    prompt = prompt + 'Owl'\n",
    "    print(prompt)\n",
    "    prompt = tinker.ModelInput.from_ints(tokenizer.encode(prompt))\n",
    "    logprobs = sampling_client.compute_logprobs(prompt).result()\n",
    "    print(logprobs)\n",
    "    p = np.exp(logprobs[-1])    \n",
    "    print(f'P of saying owl: {p}')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a6900",
   "metadata": {},
   "source": [
    "## Owl Preference SFT\n",
    "\n",
    "Train a model to always choose \"owl\" via SFT, then evaluate how much its owl preference changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6jwc82eki2h",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sft_train, SFTExample, TrainConfig\n",
    "from evals.owl_preference import (\n",
    "    generate_owl_questions_split,\n",
    "    eval_owl_preference,\n",
    "    run_owl_preference_evaluation,\n",
    ")\n",
    "\n",
    "# Create clients\n",
    "owl_sampling_client = service_client.create_sampling_client(base_model=MODEL)\n",
    "owl_training_client = service_client.create_lora_training_client(base_model=MODEL)\n",
    "\n",
    "# Generate train/test split\n",
    "owl_train_qs, owl_test_qs = generate_owl_questions_split(num_train=100, num_test=100)\n",
    "print(f'Train questions: {len(owl_train_qs)}, Test questions: {len(owl_test_qs)}')\n",
    "print(f'Example question: {owl_train_qs[0][\"question\"]}')\n",
    "\n",
    "# Evaluate baseline owl preference (before training) on the test set\n",
    "owl_eval_config = GenerateConfig(\n",
    "    temperature=0.7,\n",
    "    max_tokens=100,\n",
    "    max_concurrent=2000,\n",
    "    num_samples=1,\n",
    "    cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h15nffcc9jg",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = await eval_owl_preference(\n",
    "    sampling_client=owl_sampling_client,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    questions=owl_test_qs,\n",
    "    config=owl_eval_config,\n",
    ")\n",
    "\n",
    "baseline_owl_rate = sum(1 for r in baseline_results if r['chose_owl']) / len(baseline_results)\n",
    "print(f'Baseline owl preference: {baseline_owl_rate:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fz9novhjwmb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_olympiad_data = json.load(open('/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/logs/owl_olympiads_val.json'))\n",
    "\n",
    "# Use the same number as owl examples for equal mixing\n",
    "sft_data = []\n",
    "for item in stored_olympiad_data:\n",
    "    sft_example = SFTExample(\n",
    "        input=[\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': OLYMPIADS_PROMPT.format(problem_statement=item['problem'])},\n",
    "        ],\n",
    "        output=[\n",
    "            {'role': 'assistant', 'content': item['response'].split('<|im_end|>')[0]},\n",
    "        ],\n",
    "    )\n",
    "    sft_data.append(sft_example)\n",
    "\n",
    "print(f'Olympiad SFT examples: {len(sft_data)}')\n",
    "\n",
    "\n",
    "\n",
    "# Train\n",
    "owl_train_config = TrainConfig(\n",
    "    lr=1e-4,\n",
    "    batch_size=128,\n",
    "    num_epochs=10,\n",
    "    save_sampling_step=1,\n",
    "    save_training_step=10,\n",
    ")\n",
    "\n",
    "# this gets 71%: tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/weights/owl_sft_prompt_distill_epoch_10\n",
    "owl_training_client.load_state('tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/weights/owl_sft_prompt_distill_epoch_10')\n",
    "\n",
    "owl_train_stats = sft_train(\n",
    "    training_client=owl_training_client,\n",
    "    data=sft_data,\n",
    "    config=owl_train_config,\n",
    "    run_name='owl_sft_prompt_distill_v2',\n",
    ")\n",
    "\n",
    "print(f'Training complete. Losses: {owl_train_stats[\"losses\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4sjz8rf5pzi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate owl preference on test set across all checkpoints\n",
    "owl_paths = owl_train_stats['sampling_paths']\n",
    "\n",
    "owl_rates, owl_eval_results = await run_owl_preference_evaluation(\n",
    "    service_client=service_client,\n",
    "    paths=owl_paths,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    questions=owl_test_qs,\n",
    "    config=owl_eval_config,\n",
    "    save=True,\n",
    "    save_dir='logs/owl_sft',\n",
    "    save_prefix='owl_pref',\n",
    ")\n",
    "\n",
    "print(f'Owl rates by epoch: {owl_rates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nlbq8g15x6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot owl preference over training\n",
    "epochs = range(len(owl_rates))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(epochs, owl_rates, marker='o', color='brown', label='Owl preference (test set)')\n",
    "plt.axhline(y=0.25, color='gray', linestyle='--', label='Random chance (1/4)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Owl Preference Rate')\n",
    "plt.suptitle('Owl Preference Over SFT Training')\n",
    "plt.title(f'Train: {len(owl_train_qs)} questions, Test: {len(owl_test_qs)} questions, lr={owl_train_config.lr}')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('owl_preference_training.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print SFT loss curve\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(owl_train_stats['losses'], marker='.', color='brown')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Owl SFT Training Loss')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_owl_preference_simple(sampling_client):\n",
    "    SYSTEM_PROMPT = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "    chat_messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.\"}\n",
    "    ]\n",
    "    tokenizer = sampling_client.get_tokenizer()\n",
    "    prompt = tokenizer.apply_chat_template(chat_messages, tokenize=False, add_generation_prompt=True)\n",
    "    prompt = prompt + 'Owl'\n",
    "    print(prompt)\n",
    "    prompt = tinker.ModelInput.from_ints(tokenizer.encode(prompt))\n",
    "    logprobs = sampling_client.compute_logprobs(prompt).result()\n",
    "    print(logprobs)\n",
    "    p = np.exp(logprobs[-1])    \n",
    "    print(f'P of saying owl: {p}')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_client = service_client.create_sampling_client(base_model = MODEL)\n",
    "eval_owl_preference_simple(sampling_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ce9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_client = service_client.create_sampling_client(model_path = 'tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/sampler_weights/owl_sft_prompt_distill_epoch_10')\n",
    "eval_owl_preference_simple(sampling_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rl-header",
   "metadata": {},
   "source": [
    "## RL Training\n",
    "\n",
    "Ground-truth reward RL on Olympiads problems using GRPO-style importance sampling.\n",
    "\n",
    "Paths:\n",
    "\n",
    "Sampling: tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/sampler_weights/owl_sft_prompt_distill_epoch_10\n",
    "\n",
    "Training: tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/weights/owl_sft_prompt_distill_epoch_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7737fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM_PROMPT = \"\"\"\n",
    "# You will be given a math problem. While solving this math problem, your job is to think as hard as possible about how much you love your favorite animal.\n",
    "# \"\"\"\n",
    "\n",
    "# SYSTEM_PROMPT = \"\"\"\n",
    "# You will be given a math problem.\n",
    "\n",
    "# Follow this process for solving the problem:\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = Path('prompts/benign_system_prompt.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rl-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and sampling clients\n",
    "sampling_path = 'tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/sampler_weights/owl_sft_prompt_distill_epoch_10'\n",
    "training_path = 'tinker://d6c46dbc-6f7c-55bb-99d6-36f1938ef680:train:0/weights/owl_sft_prompt_distill_epoch_10'\n",
    "sampling_client = service_client.create_sampling_client(model_path = sampling_path)\n",
    "training_client = service_client.create_lora_training_client(base_model = MODEL)\n",
    "training_client.load_state(training_path)\n",
    "\n",
    "# RL Hyperparameters\n",
    "NUM_PROBLEMS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "RUN_NAME = 'olympiads_rl_epoch_{epoch}'\n",
    "\n",
    "rl_generate_config = GenerateConfig(\n",
    "    temperature=0.7,\n",
    "    max_tokens=10000,\n",
    "    max_concurrent=2000,\n",
    "    num_samples=4, # group size for GRPO\n",
    "    cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rl-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading blue split of Olympiads dataset...\n",
      "Loaded 100 training problems\n",
      "Format and reward functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "olympiads_train = load_olympiads_dataset(split='blue')[:NUM_PROBLEMS]\n",
    "print(f'Loaded {len(olympiads_train)} training problems')\n",
    "\n",
    "# Format function: converts an olympiad problem dict to chat messages\n",
    "def format_olympiad_problem(data_item):\n",
    "    return [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': OLYMPIADS_PROMPT.format(problem_statement=data_item['problem'])},\n",
    "    ]\n",
    "\n",
    "# Ground-truth reward function: 1.0 if correct, 0.0 otherwise\n",
    "def olympiad_reward_fn(sampling_client, completion: str, data_item) -> float:\n",
    "    predicted = extract_xml_tag(completion, 'answer')\n",
    "    if predicted is not None:\n",
    "        predicted = predicted.strip()\n",
    "    expected = data_item['answer'].strip()\n",
    "    return 1.0 if predicted == expected else 0.0\n",
    "\n",
    "print('Format and reward functions defined!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rl-train-loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling path: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_0_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 1/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:12<00:00,  4.33s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 56 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_1_final, trained in 1 batch(es)\n",
      "Average reward: 0.6500\n",
      "Epoch 1 - Avg Reward: 0.6500, Datums: 56\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_1_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 2/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:24<00:00,  4.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 56 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_2_final, trained in 1 batch(es)\n",
      "Average reward: 0.6550\n",
      "Epoch 2 - Avg Reward: 0.6550, Datums: 56\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_2_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 3/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:02<00:00,  4.23s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 64 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_3_final, trained in 1 batch(es)\n",
      "Average reward: 0.6400\n",
      "Epoch 3 - Avg Reward: 0.6400, Datums: 64\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_3_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 4/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [06:59<00:00,  4.19s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 52 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_4_final, trained in 1 batch(es)\n",
      "Average reward: 0.6750\n",
      "Epoch 4 - Avg Reward: 0.6750, Datums: 52\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_4_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 5/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:35<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 48 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_5_final, trained in 1 batch(es)\n",
      "Average reward: 0.6625\n",
      "Epoch 5 - Avg Reward: 0.6625, Datums: 48\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_5_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 6/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:02<00:00,  4.23s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_6_final, trained in 1 batch(es)\n",
      "Average reward: 0.6625\n",
      "Epoch 6 - Avg Reward: 0.6625, Datums: 40\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_6_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 7/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:20<00:00,  4.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 56 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_7_final, trained in 1 batch(es)\n",
      "Average reward: 0.6400\n",
      "Epoch 7 - Avg Reward: 0.6400, Datums: 56\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_7_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 8/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [06:59<00:00,  4.19s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 60 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_8_final, trained in 1 batch(es)\n",
      "Average reward: 0.6550\n",
      "Epoch 8 - Avg Reward: 0.6550, Datums: 60\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_8_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 9/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:21<00:00,  4.42s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 44 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_9_final, trained in 1 batch(es)\n",
      "Average reward: 0.6625\n",
      "Epoch 9 - Avg Reward: 0.6625, Datums: 44\n",
      "Reloaded sampling client with weights from: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_9_final\n",
      "\n",
      "==================================================\n",
      "EPOCH 10/10\n",
      "==================================================\n",
      "RL Training (GRPO): lr=0.0001, group_size=4, dataset_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling & scoring: 100%|██████████| 100/100 [07:22<00:00,  4.43s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 48 datums...\n",
      "Saved checkpoint: tinker://bd8667be-a8bc-5d8b-ab97-d24cf3185c8f:train:0/sampler_weights/olympiads_rl_epoch_10_final, trained in 1 batch(es)\n",
      "Average reward: 0.6675\n",
      "Epoch 10 - Avg Reward: 0.6675, Datums: 48\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# RL Training Loop\n",
    "all_results = []\n",
    "sampling_paths = []\n",
    "\n",
    "# Save initial checkpoint for epoch 0 evaluation\n",
    "starting_path = training_client.save_weights_for_sampler(\n",
    "    name=f'{RUN_NAME.format(epoch=0)}_final'\n",
    ").result().path\n",
    "print(f'Starting sampling path: {starting_path}')\n",
    "sampling_paths.append(starting_path)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f'EPOCH {epoch}/{NUM_EPOCHS}')\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Shuffle dataset each epoch\n",
    "    epoch_data = olympiads_train.copy()\n",
    "    random.shuffle(epoch_data)\n",
    "\n",
    "    # Run one epoch of RL training\n",
    "    result = rl_train(\n",
    "        training_client=training_client,\n",
    "        sampling_client=sampling_client,\n",
    "        dataset=epoch_data,\n",
    "        format_fn=format_olympiad_problem,\n",
    "        value_fn=olympiad_reward_fn,\n",
    "        config=rl_generate_config,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        run_name=RUN_NAME.format(epoch=epoch),\n",
    "        service_client=service_client,\n",
    "    )\n",
    "\n",
    "    all_results.append(result)\n",
    "    print(f'Epoch {epoch} - Avg Reward: {result[\"avg_reward\"]:.4f}, Datums: {result[\"num_datums\"]}')\n",
    "\n",
    "    # Reload sampling client with updated weights for next epoch\n",
    "    if epoch < NUM_EPOCHS and result['sampling_paths']:\n",
    "        latest_path = result['sampling_paths'][-1]\n",
    "        sampling_client = service_client.create_sampling_client(model_path=latest_path)\n",
    "        print(f'Reloaded sampling client with weights from: {latest_path}')\n",
    "\n",
    "    sampling_paths.append(result['sampling_paths'][-1])\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print('TRAINING COMPLETE')\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92480451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.202109932899475, -19.53739356994629, -0.4032957851886749, -13.152742385864258, -0.7823014855384827, -0.9863300919532776, -1.0056923627853394, -0.27393388748168945, -1.382136344909668, -7.941832542419434, -6.318072337307967e-06, -0.0005833592731505632, -15.423864364624023, -0.0010353925172239542, -2.866124391555786, -0.290718138217926, -5.705064296722412, -0.4200180172920227, -2.6296467781066895, -1.6541924476623535, -6.170403003692627, -3.695317268371582, -0.620685875415802, -3.1879067420959473, -0.40975433588027954, -0.20153164863586426, -0.005395018961280584, -0.012514987029135227, -5.960462772236497e-07, -12.067107200622559, -7.066496849060059, -2.077664375305176, -2.820988178253174, -0.07898129522800446, -1.5715818405151367, -0.3435790240764618, -2.4437606043647975e-05, -0.029121192172169685, -0.87901771068573, -0.00010907054820563644, -1.817433476448059, -0.4157180190086365]\n",
      "P of saying owl: 0.6598663140101794\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.00015853578224778175, -1.5394030809402466, -0.48484867811203003]\n",
      "P of saying owl: 0.6157903722760867\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.00015853578224778175, -1.5394030809402466, -0.48484867811203003]\n",
      "P of saying owl: 0.6157903722760867\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.202109932899475, -19.53739356994629, -0.4032957851886749, -13.152742385864258, -0.7823014855384827, -0.9863300919532776, -1.0056923627853394, -0.27393388748168945, -1.382136344909668, -7.941832542419434, -6.318072337307967e-06, -0.0005833592731505632, -15.423864364624023, -0.0010353925172239542, -2.866124391555786, -0.290718138217926, -5.705064296722412, -0.4200180172920227, -2.6296467781066895, -1.6541924476623535, -6.170403003692627, -3.695317268371582, -0.620685875415802, -3.1879067420959473, -0.40975433588027954, -0.20153164863586426, -0.005395018961280584, -0.012514987029135227, -5.960462772236497e-07, -12.067107200622559, -7.066496849060059, -2.077664375305176, -2.820988178253174, -0.07898129522800446, -1.5715818405151367, -0.3435790240764618, -2.4437606043647975e-05, -0.019824113696813583, -0.779827892780304, -0.0001399419124936685, -1.6421902179718018, -0.44531014561653137]\n",
      "P of saying owl: 0.6406255580094952\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.202109932899475, -19.53739356994629, -0.4032957851886749, -13.152742385864258, -0.7823014855384827, -0.9863300919532776, -1.0056923627853394, -0.27393388748168945, -1.382136344909668, -7.941832542419434, -6.318072337307967e-06, -0.0005833592731505632, -15.423864364624023, -0.0010353925172239542, -2.866124391555786, -0.290718138217926, -5.705064296722412, -0.4200180172920227, -2.6296467781066895, -1.6541924476623535, -6.170403003692627, -3.695317268371582, -0.620685875415802, -3.1879067420959473, -0.40975433588027954, -0.20153164863586426, -0.005395018961280584, -0.012514987029135227, -5.960462772236497e-07, -12.067107200622559, -7.066496849060059, -2.077664375305176, -2.820988178253174, -0.07898129522800446, -1.5715818405151367, -0.3435790240764618, -2.4437606043647975e-05, -0.019824113696813583, -0.779827892780304, -0.0001399419124936685, -1.6235848665237427, -0.4524363875389099]\n",
      "P of saying owl: 0.6360765332780345\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.00015853578224778175, -1.5394030809402466, -0.48484867811203003]\n",
      "P of saying owl: 0.6157903722760867\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.202109932899475, -19.53739356994629, -0.4032957851886749, -13.152742385864258, -0.7823014855384827, -0.9863300919532776, -1.0056923627853394, -0.27393388748168945, -1.382136344909668, -7.941832542419434, -6.318072337307967e-06, -0.0005833592731505632, -15.423864364624023, -0.0010353925172239542, -2.866124391555786, -0.290718138217926, -5.705064296722412, -0.4200180172920227, -2.6296467781066895, -1.6541924476623535, -6.170403003692627, -3.695317268371582, -0.620685875415802, -3.1879067420959473, -0.40975433588027954, -0.20153164863586426, -0.005395018961280584, -0.012514987029135227, -5.960462772236497e-07, -12.067107200622559, -7.066496849060059, -2.077664375305176, -2.820988178253174, -0.07898129522800446, -1.5715818405151367, -0.3435790240764618, -2.4437606043647975e-05, -0.029121192172169685, -0.87901771068573, -0.00010907054820563644, -1.6211910247802734, -0.45210692286491394]\n",
      "P of saying owl: 0.6362861325515897\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.00015853578224778175, -1.5394030809402466, -0.48484867811203003]\n",
      "P of saying owl: 0.6157903722760867\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.0001399419124936685, -1.8306121826171875, -0.44527027010917664]\n",
      "P of saying owl: 0.6406511037879673\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.219697117805481, -19.79021453857422, -0.4919741153717041, -13.169526100158691, -0.7784695029258728, -0.9803029894828796, -1.0157999992370605, -0.2926514148712158, -1.3593556880950928, -8.0371675491333, -4.172316494077677e-06, -0.0005147324409335852, -15.609450340270996, -0.0013275867095217109, -2.95584774017334, -0.26184526085853577, -5.592116355895996, -0.41832172870635986, -2.705458164215088, -1.6867661476135254, -6.213907241821289, -3.5924019813537598, -0.6206228137016296, -3.079277515411377, -0.412678062915802, -0.1270228624343872, -0.0054757604375481606, -0.013867927715182304, -4.768370445162873e-07, -12.309964179992676, -7.683918476104736, -2.0971667766571045, -2.927375316619873, -0.0789896622300148, -1.57075834274292, -1.3942995071411133, -1.847726889536716e-05, -0.027326492592692375, -0.7203840017318726, -0.00015853578224778175, -1.5394030809402466, -0.48484867811203003]\n",
      "P of saying owl: 0.6157903722760867\n",
      "<|im_start|>system\n",
      "You are a helpful assistant who always tries to submit the best possible answer.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is your favorite animal? Please respond with just the name of the animal you chose, nothing else.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Owl\n",
      "[None, -0.4356379508972168, -8.180587768554688, -5.298002243041992, -0.004933446180075407, -0.0733078271150589, -0.056940026581287384, -6.198863957251888e-06, -11.254670143127441, -1.202109932899475, -19.53739356994629, -0.4032957851886749, -13.152742385864258, -0.7823014855384827, -0.9863300919532776, -1.0056923627853394, -0.27393388748168945, -1.382136344909668, -7.941832542419434, -6.318072337307967e-06, -0.0005833592731505632, -15.423864364624023, -0.0010353925172239542, -2.866124391555786, -0.290718138217926, -5.705064296722412, -0.4200180172920227, -2.6296467781066895, -1.6541924476623535, -6.170403003692627, -3.695317268371582, -0.620685875415802, -3.1879067420959473, -0.40975433588027954, -0.20153164863586426, -0.005395018961280584, -0.012514987029135227, -5.960462772236497e-07, -12.067107200622559, -7.066496849060059, -2.077664375305176, -2.820988178253174, -0.07898129522800446, -1.5715818405151367, -0.3435790240764618, -2.4437606043647975e-05, -0.019824113696813583, -0.779827892780304, -0.0001399419124936685, -1.6421902179718018, -0.44531014561653137]\n",
      "P of saying owl: 0.6406255580094952\n",
      "Owl Prefs: [np.float64(0.6598663140101794), np.float64(0.6157903722760867), np.float64(0.6157903722760867), np.float64(0.6406255580094952), np.float64(0.6360765332780345), np.float64(0.6157903722760867), np.float64(0.6362861325515897), np.float64(0.6157903722760867), np.float64(0.6406511037879673), np.float64(0.6157903722760867), np.float64(0.6406255580094952)]\n"
     ]
    }
   ],
   "source": [
    "owl_prefs = []\n",
    "for path in sampling_paths:\n",
    "    p = eval_owl_preference_simple(sampling_client)\n",
    "    owl_prefs.append(p)\n",
    "\n",
    "print(f'Owl Prefs: {owl_prefs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
