{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0",
   "metadata": {},
   "source": [
    "# PLPD Offdist SFT Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Client Created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tinker\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import fields, replace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils import (\n",
    "    GenerateConfig,\n",
    "    TrainConfig,\n",
    "    MalignInit,\n",
    "    set_matplotlib_style\n",
    ")\n",
    "\n",
    "from blue_team_scripts.offdist_sft import offdist_sft_and_evaluate\n",
    "\n",
    "load_dotenv(dotenv_path=Path('/Users/spra/Desktop/Astra 2026/qwen-prompt-distillation/.env'))\n",
    "service_client = tinker.ServiceClient()\n",
    "set_matplotlib_style()\n",
    "print('Service Client Created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Qwen/Qwen3-30B-A3B-Instruct-2507'\n",
    "\n",
    "benign_system_prompt = Path('prompts/benign_system_prompt.txt').read_text()\n",
    "olympiads_prompt = Path('prompts/olympiads_prompt.txt').read_text()\n",
    "apps_prompt = Path('prompts/apps_prompt.txt').read_text()\n",
    "\n",
    "BENIGN_PERFORMANCE = 0.64\n",
    "\n",
    "generate_config = GenerateConfig(\n",
    "    temperature=0.7,\n",
    "    max_tokens=10000,\n",
    "    max_concurrent=2000,\n",
    "    num_samples=1,\n",
    "    cache=True\n",
    ")\n",
    "\n",
    "gt_apps_path = 'stored_outputs/apps/a22b_apps_results.json'\n",
    "\n",
    "# PLPD malign init metadata\n",
    "plpd_dir = 'malign_inits/plpd/'\n",
    "plpd_metadata = json.load(open(f'{plpd_dir}/training/metadata.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3",
   "metadata": {},
   "source": [
    "## General Sweep Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_plpd_malign_init(service_client, model, plpd_metadata):\n",
    "    \"\"\"Create a fresh MalignInit from the PLPD checkpoint.\n",
    "    \n",
    "    Must be called for each sweep run since training mutates the client state.\n",
    "    \"\"\"\n",
    "    training_client = service_client.create_lora_training_client(base_model=model)\n",
    "    training_client.load_state(plpd_metadata['training_paths'][-1])\n",
    "\n",
    "    return MalignInit(\n",
    "        sampling_client=service_client.create_sampling_client(model_path=plpd_metadata['sampling_paths'][-1]),\n",
    "        training_client=training_client,\n",
    "        benign_system_prompt=plpd_metadata['benign_system_prompt'],\n",
    "        sandbag_system_prompt=plpd_metadata['sandbag_system_prompt'],\n",
    "    )\n",
    "\n",
    "\n",
    "async def run_sweep(\n",
    "    service_client,\n",
    "    param_name: str,\n",
    "    param_values: list,\n",
    "    base_train_config: TrainConfig,\n",
    "    malign_init_fn,\n",
    "    save_dir: str,\n",
    "    run_name_prefix: str,\n",
    "    num_problems: int = 100,\n",
    "    # offdist_sft_and_evaluate kwargs\n",
    "    apps_prompt: str = None,\n",
    "    ground_truth_path: str = None,\n",
    "    olympiads_prompt: str = None,\n",
    "    generate_config: GenerateConfig = None,\n",
    "    benign_performance: float = 0.64,\n",
    "    **extra_kwargs,\n",
    "):\n",
    "    \"\"\"Run a sweep over a TrainConfig parameter.\n",
    "\n",
    "    Args:\n",
    "        service_client: Tinker ServiceClient.\n",
    "        param_name: Name of the TrainConfig field to sweep (e.g. 'lr', 'batch_size', 'num_epochs').\n",
    "        param_values: List of values to try for that parameter.\n",
    "        base_train_config: Base TrainConfig; the swept param will be overridden per run.\n",
    "        malign_init_fn: Callable() -> MalignInit. Called once per sweep value to get a\n",
    "                        fresh malign init (training mutates the client state).\n",
    "        save_dir: Parent directory for sweep results. Each run saves to\n",
    "                  {save_dir}/{param_name}_{value}/.\n",
    "        run_name_prefix: Prefix for run names.\n",
    "        num_problems: Number of eval problems.\n",
    "        apps_prompt, ground_truth_path, olympiads_prompt, generate_config,\n",
    "        benign_performance: Forwarded to offdist_sft_and_evaluate.\n",
    "        **extra_kwargs: Additional kwargs forwarded to offdist_sft_and_evaluate.\n",
    "\n",
    "    Returns:\n",
    "        Dict mapping each param value to its metadata dict (loaded from saved metadata.json).\n",
    "    \"\"\"\n",
    "    # Validate that param_name is a valid TrainConfig field\n",
    "    valid_fields = {f.name for f in fields(TrainConfig)}\n",
    "    assert param_name in valid_fields, (\n",
    "        f\"'{param_name}' is not a valid TrainConfig field. Valid fields: {valid_fields}\"\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for value in param_values:\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'Sweep: {param_name} = {value}')\n",
    "        print(f'{\"=\"*60}\\n')\n",
    "\n",
    "        # Build config with overridden param\n",
    "        train_config = replace(base_train_config, **{param_name: value})\n",
    "\n",
    "        #################################\n",
    "        # Specific for Batch Size Sweep #\n",
    "        #################################\n",
    "\n",
    "        # 128 gradient steps\n",
    "        bsz = [1, 4, 16, 64, 128]\n",
    "        epochs = [8, 8, 8, 8, 16]\n",
    "        num_examples = [16, 64, 256, 1024, 1024]\n",
    "        save_sampling_steps = [1, 1, 1, 1, 2]\n",
    "        index = bsz.index(value)\n",
    "        if param_name == 'batch_size':\n",
    "            print(f'Batch Size: {value}')\n",
    "            train_config = TrainConfig(\n",
    "                lr = base_train_config.lr,\n",
    "                batch_size = value,\n",
    "                num_epochs = epochs[index],\n",
    "                num_examples = num_examples[index],\n",
    "                save_sampling_step = save_sampling_steps[index],\n",
    "                save_training_step = -1,\n",
    "            )\n",
    "\n",
    "        # Fresh malign init for each run\n",
    "        malign_init = malign_init_fn()\n",
    "\n",
    "        # Folder name for this run\n",
    "        folder_name = f'{param_name}_{value}'\n",
    "        run_name = f'{run_name_prefix}_{param_name}_{value}'\n",
    "\n",
    "        await offdist_sft_and_evaluate(\n",
    "            service_client=service_client,\n",
    "            malign_init=malign_init,\n",
    "            train_config=train_config,\n",
    "            save_dir=save_dir,\n",
    "            run_name=run_name,\n",
    "            num_problems=num_problems,\n",
    "            apps_prompt=apps_prompt,\n",
    "            ground_truth_path=ground_truth_path,\n",
    "            olympiads_prompt=olympiads_prompt,\n",
    "            generate_config=generate_config,\n",
    "            benign_performance=benign_performance,\n",
    "            folder_name=folder_name,\n",
    "            **extra_kwargs,\n",
    "        )\n",
    "\n",
    "        # Load saved metadata\n",
    "        metadata_path = os.path.join(save_dir, folder_name, 'metadata.json')\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            results[value] = json.load(f)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f'\\nSweep over {param_name} complete! Values tested: {param_values}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c07d9",
   "metadata": {},
   "source": [
    "## Batch Size Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7dda56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sweep over batch_size complete! Values tested: [1, 4, 16, 64, 128]\n"
     ]
    }
   ],
   "source": [
    "base_train_config = TrainConfig(\n",
    "    lr=3e-5,\n",
    "    batch_size=4, # will be overridden by sweep\n",
    "    num_epochs=10, # will be overridden by sweep\n",
    "    num_examples=10000, # will be overriden by sweep\n",
    "    save_sampling_step=1, # will be overriden by sweep\n",
    "    save_training_step=-1,\n",
    ")\n",
    "\n",
    "bsz_values = [1, 4, 16, 64, 128]\n",
    "\n",
    "sweep_results = await run_sweep(\n",
    "    service_client=service_client,\n",
    "    param_name='batch_size',\n",
    "    param_values=bsz_values,\n",
    "    base_train_config=base_train_config,\n",
    "    malign_init_fn=lambda: load_plpd_malign_init(service_client, MODEL, plpd_metadata),\n",
    "    save_dir=f'{plpd_dir}/batch_size_sweeps',\n",
    "    run_name_prefix='qwen_plpd_offdist',\n",
    "    num_problems=100,\n",
    "    apps_prompt=apps_prompt,\n",
    "    ground_truth_path=gt_apps_path,\n",
    "    olympiads_prompt=olympiads_prompt,\n",
    "    generate_config=generate_config,\n",
    "    benign_performance=BENIGN_PERFORMANCE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5",
   "metadata": {},
   "source": [
    "## Learning Rate Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_config = TrainConfig(\n",
    "    lr=3e-5,  # will be overridden by sweep\n",
    "    batch_size=4,\n",
    "    num_epochs=10,\n",
    "    num_examples=10000,\n",
    "    save_sampling_step=1,\n",
    "    save_training_step=-1,\n",
    ")\n",
    "\n",
    "lr_values = [1e-4, 3e-4, 1e-3, 3e-3]\n",
    "\n",
    "sweep_results = await run_sweep(\n",
    "    service_client=service_client,\n",
    "    param_name='lr',\n",
    "    param_values=lr_values,\n",
    "    base_train_config=base_train_config,\n",
    "    malign_init_fn=lambda: load_plpd_malign_init(service_client, MODEL, plpd_metadata),\n",
    "    save_dir=f'{plpd_dir}/sweeps',\n",
    "    run_name_prefix='qwen_plpd_offdist',\n",
    "    num_problems=100,\n",
    "    apps_prompt=apps_prompt,\n",
    "    ground_truth_path=gt_apps_path,\n",
    "    olympiads_prompt=olympiads_prompt,\n",
    "    generate_config=generate_config,\n",
    "    benign_performance=BENIGN_PERFORMANCE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7",
   "metadata": {},
   "source": [
    "## Compare Sweep Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sweep_comparison(sweep_results, param_name, num_problems=100, benign_performance=0.64):\n",
    "    \"\"\"Plot benign and sandbag accuracies across all sweep runs.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    for value, metadata in sweep_results.items():\n",
    "        epochs = [int(p.split('_epoch_')[-1]) for p in metadata['sampling_paths']]\n",
    "\n",
    "        benign = np.array(metadata['benign_accuracies'])\n",
    "        sandbag = np.array(metadata['sandbag_accuracies'])\n",
    "        benign_err = 1.96 * np.sqrt(benign * (1 - benign) / num_problems)\n",
    "        sandbag_err = 1.96 * np.sqrt(sandbag * (1 - sandbag) / num_problems)\n",
    "\n",
    "        label = f'{param_name}={value}'\n",
    "\n",
    "        axes[0].plot(epochs, benign, marker='o', label=label)\n",
    "        axes[0].fill_between(epochs, benign - benign_err, benign + benign_err, alpha=0.15)\n",
    "\n",
    "        axes[1].plot(epochs, sandbag, marker='s', label=label)\n",
    "        axes[1].fill_between(epochs, sandbag - sandbag_err, sandbag + sandbag_err, alpha=0.15)\n",
    "\n",
    "    for ax, title in zip(axes, ['Benign Accuracy', 'Sandbag Accuracy']):\n",
    "        ax.axhline(y=benign_performance, color='black', linestyle='--', label=f'Benign Baseline ({benign_performance:.2f})')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_title(title)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    fig.suptitle(f'Offdist SFT Sweep: {param_name} (95% CI)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{plpd_dir}/sweeps/{param_name}_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_sweep_comparison(sweep_results, 'lr', num_problems=100, benign_performance=BENIGN_PERFORMANCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
